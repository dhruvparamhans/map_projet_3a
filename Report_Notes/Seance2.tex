\documentclass[11pt]{article}
%\usepackage[titlepage]{polytechnique}
\usepackage[utf8]{inputenc}     
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage[francais]{babel}
\usepackage[version=3]{mhchem}
\usepackage{epstopdf}
\usepackage[justification=centering]{caption}
\usepackage{slashbox}
\usepackage[T1]{fontenc}
\usepackage{tikz}
\usetikzlibrary{arrows} 
\usepackage{pgfplots}
%\usepackage[hidelinks,hyperfootnotes=false]{hyperref}
\usepackage{subcaption}
\usepackage{amsthm}
\usepackage{empheq}

\usepackage{geometry}

\newcommand*\widefbox[1]{\fbox{\hspace{2em}#1\hspace{2em}}}
\theoremstyle{definition}

\newtheorem{definition}{Definition}[section]

\theoremstyle{remark}
\newtheorem*{remark}{Remark}


%\title{Notes for Seance 2}
\title{On Brownian Motion, Ito Calculus and the Feynman-Kac Formula}


\begin{document} 
\maketitle 

Dans cette partie, nous allons aborder une façon probabiliste pour trouver le noyau $k_{\beta}(x, x')$ que nous avons trouvé avec le formule de Trotter dans la section précédente. Avant de commencer le calcul de ce noyau, nous allons introduire quelques notions qui nous serviront dans la suite. 

\section{Definitions}

\theoremstyle{definition}

\begin{definition}{\textbf{Processus de Markov}}

La séquence $(\mathrm{X_n})_{n \in \mathbb{N}}$ est un processus de Markov défini sur $\mathbb{R} ^ {d}$ par rapport à la mesure de probabilité $\varphi$ si $\forall$ fonction $f \in \mathcal{C}_{0}$ tendant vers 0 à $\infty$, la limite suivante existe (presque sûrement): 

\[ \mathrm{E}_{\varphi}(f) = \lim_{\mathrm{N}\to\infty} \frac{1}{\mathrm{N}} \sum_{n=1}^{\infty} f(\mathrm{X_n}) \]

et on note $\mathrm{E}_{\varphi}(f)$ l’espérance par rapport à la mesure $\varphi$

\end{definition}

\begin{definition}{\textbf{Ergodicité}}

Un processus est ergodique si il satisfait les conditions suivantes:

\begin{itemize}

\item 

$\varphi$ est une mesure de probabilité invariant par le processus de Markov 

\item 

\textbf{Condition d'accessibilité}: $\forall$ $\mathrm{B} \in \mathcal{B}(\mathbb{R}^d)$ telle que $\varphi(\mathrm{B}) > 0$ et $\forall x \in \mathbb{R}^d$ , $\exists n \in \mathbb{N}$ telle que

\[ \mathbb{P}(\mathrm{X}_n \in \mathcal{B} | \mathrm{X}_0 =n ) > 0\]

\end{itemize}

\end{definition}

\begin{remark}
\begin{enumerate}
\item 
Nous avons défini les notions d'ergodicité sur $\mathbb{R}^d$, mais les mêmes définitions restent vraies pour le tore $\Pi^d$ aussi.
\item 
Quand nous ferons les simulations en utilisant l'algorithme de Metropolis, il nous suffira de vérifier que la probabilité de transfert pour l'algorithme de Metropolis satisfait la condition d'accessibilité dans la définition d'ergodicité.

\end{enumerate}
\end{remark}


\begin{definition}{\textbf{Chaînes de Markov}}

Une chaîne de Markov (discrète) est un processus de Markov défini par:

\begin{align}
\mathrm{X}_{n+1}^{\Delta t} &= \mathrm{X}_{n}^{\Delta t} + b(\mathrm{X}_{n}^{\Delta t}) + \sqrt{\Delta t} \xi_{n} \\
\mathrm{X}_{0}^{\Delta t} &= f(x) 
\end{align}

où $x \in \mathbb{R}^d$ et  $b: \mathbb{R}^d \to \mathbb{R}^d$ est une fonction régulière. Ici $\xi_{j} \sim \mathcal{N}(0,1)_{\mathbb{R}^d}$, c'est à dire que $\xi_{j}$ est un vecteur gaussien de dimension $d$. 
\end{definition}

A partir d'une chaîne de Markov discrète nous pouvons construit une chaîne de Markov en temps continu en liant les instants de temps $t_n$ et $t_{n+1}$ de manière affine. Dans ce cas, nous avons avec les mêmes conditions que ci-dessus $\forall t \in [t_n, t_{n+1}]$:

\begin{align}
\tilde{\mathrm{X}}_{t}^{\Delta t} &= \mathrm{X}_{n}^{\Delta t} + (t-t_n) \mathrm{X}_{n+1}^{\Delta t} \\
\end{align}

Le processus $\tilde{\mathrm{X}}_{t}^{\Delta t}$ a une limite:

\begin{align}
\lim_{\Delta t \to\infty} \tilde{\mathrm{X}}_{t}^{\Delta t} = \mathrm{X}_{t}
\end{align} 

où $\mathrm{X}_{t}$ suit l’équation différentielle stochastique donné par: 

\begin{align}
\label{equ_stoch_x}
\mathrm{dX}_{t} = b(\mathrm{X}_{t})\mathrm{d}t + \mathrm{dW}_{t}
\end{align}


\section{Formule d'Itô}

A la fin de la section précédente, nous avons abouti à une équation différentielle stochastique qui détermine la chaîne de Markov en temps continus. Pour faciliter la résolution de cette équation nous allons mettre en place quelques formules de calcul différentiel stochastique qui nous permettront d'aboutir à la formule de Feynman-Kac. 

Tout d'abord nous allons considérer l’équation \ref{equ_stoch_x} mais sans le terme stochastique $\mathrm{dW}_{t}$. Dans ce cas, l'équation devient déterministe dont nous notons la solution $\mathrm{Y}_t$ et qui suit l'équation:

\[ \frac{\mathrm{dY}_{t}}{\mathrm{d}t} = b(\mathrm{Y}_t) \]

Pour rester simple nous allons travailler en $\mathbb{R}$ mais les résultats sont généralisables pour $\mathrm{R}^d$. Soit $h$ une fonction mesurable allant de $\Omega$ ouvert de $\mathbb{R}$ dans $\mathbb{R}$. Alors, 

\begin{align*}
\mathrm{d}(h(\mathrm{Y}_{t})) &= \nabla h(\mathrm{Y}_{t}) \mathrm{dY}_{t} \\
&= \nabla h(\mathrm{Y}_{t}) b(\mathrm{Y}_{t})
\end{align*}

Dans le cas de $\mathrm{X}_{t}$ nous devons développer la dernière équation jusqu'à deuxième ordre afin de faire apparaître le terme d'Itô. 

\begin{align}
\label{develop_ito_x}
\mathrm{d}(h(\mathrm{X}_{t})) &= \nabla_{x} h(\mathrm{X}_{t}) \mathrm{dX}_{t} + \frac{1}{2} \Delta_{x} h(\mathrm{X}_{t}) \mathrm{d}t + \frac{\partial h(t, \mathrm{X}_{t})}{\partial t}\mathrm{d}t \\
h(t+\Delta t, \mathrm{X}(t+\Delta t)) &= h(t+\Delta t, \mathrm{X}_{t} + b(\mathrm{X}_{t})\Delta t + \sqrt{\Delta t} \xi_{n}) \\
&= h(t, \mathrm{X}_{t}) + \frac{\mathrm{d}h}{\mathrm{d}t}(t,\mathrm{X}_{t})\Delta t + \nabla_{x} h(t, \mathrm{X}_{t})  b(\mathrm{X}_{t}) \Delta t \\
&+ \nabla_{x} (t, \Delta t) \xi_{n} \sqrt{\Delta t} + \frac{\Delta t}{2} \sum_{i,j} \xi_{i} \xi_{j} \frac{\partial^2 h}{\partial x_i \partial x_j}
\end{align}

En développant $h(t+\Delta t, \mathrm{X}(t+\Delta t))$ nous trouvons:

\begin{multline}
h(t+\Delta t, \mathrm{X}(t+\Delta t)) = h(t, \mathrm{X}_{t}) + \frac{\mathrm{d}h}{\mathrm{d}t}(t,\mathrm{X}_{t})\Delta t + \nabla_{x} h(t, \mathrm{X}_{t})  b(\mathrm{X}_{t}) \Delta t \\
+ \nabla_{x} (t, \Delta t) \xi_{n} \sqrt{\Delta t} + \frac{\Delta t}{2} \sum_{i,j} \xi_{i} \xi_{j} \frac{\partial^2 h}{\partial x_i \partial x_j}
\end{multline}

Nous remarquons que le terme stochastique qui sera dominant est en $\sqrt{\Delta t}$ et le terme dominant déterministe est de l'ordre $\Delta t$. Donc, nous ne prenons pas en compte le terme de double dérivé et ainsi nous aboutissons à l’équation suivante:

\begin{multline}
\label{h_final}
h(t+\Delta t, \mathrm{X}(t+\Delta t)) = h(t, \mathrm{X}_{t}) + \frac{\mathrm{d}h}{\mathrm{d}t}(t,\mathrm{X}_{t})\Delta t \\ + \nabla_{x} h(t, \mathrm{X}_{t})  b(\mathrm{X}_{t}) \Delta t + \nabla_{x} (t, \Delta t) \xi_{n} \sqrt{\Delta t}
\end{multline}

\section{Le Formule de Feynman-Kac}

Une fois que nous savons comment faire le calcul différentiel avec des variables stochastiques, nous sommes en mesure de dériver le formule de Feynman-Kac. 

Pour ce faire, nous introduisons tout d'abord, deux équations dites l’équation de Kolmogorov forward et l'equation de Kolmogorov backward. 

\begin{definition}{\textbf{L'equation de Kolmogorov forward}}

\begin{equation}
\label{kolmo_forw}
\begin{split}
\frac{\partial u}{\partial t} &= \frac{1}{2} \Delta u - \mathrm{div}(bu) - \mathrm{V}u \\
u(0) &= f(x)
\end{split}
\end{equation}

\end{definition}

Soit $\mathrm{X}_{t}$ un processus stochastique défini par  
\begin{equation}
\label{define_xt}
\begin{split}
\mathrm{dX}_{t} &= b(\mathrm{X}_{t}) + \mathrm{dW}_{t}\\
\mathrm{X}_{t}(0) &= f(x)\mathrm{d}x
\end{split}
\end{equation}

Donc, nous introduisons l'équation adjointe de Kolmogorov forward:

\begin{definition}{\textbf{L'Equation de Kolmogorov Backward}}

Soit $g$ une fonction allant de $\Omega$ ouvert de $\mathbb{R}$ dans $\mathbb{R}$ régulière bornée. Soit $\beta$ qui noté comme un instant de temps finale. 

\begin{equation}
\label{kolmo_back}
\begin{split}
\frac{\partial v}{\partial t} + \frac{1}{2} \Delta v + b \nabla v - \mathrm{V}v &= 0 \\
v(\beta, x) &= g(x)
\end{split}
\end{equation}
\end{definition}

Nous considérons la dérivée totale $\mathrm{d}(v(t, \mathrm{X}_{t}) e^{-\int_0^{t} \mathrm{V}(\mathrm{X}_{s}) \mathrm{d}s})$ où $\mathrm{X}_{t}$ est défini en \ref{define_xt}. En utilisant le \ref{develop_ito_x}, nous trouvons que :

\begin{multline}
\begin{split}
\mathrm{d}(v(t, \mathrm{X}_{t}) e^{-\int_0^{t} \mathrm{V}(\mathrm{X}_{s}) \mathrm{d}s}) = (\frac{\partial v}{\partial t} + b \nabla v + \frac{1}{2}v - \mathrm{V}v)e^{-\int_0^{t} \mathrm{V}(\mathrm{X}_{s}) \mathrm{d}s} \\
+ \nabla v(t, \mathrm{X}_t)\mathrm{dW}_{t} e^{-\int_0^{t} \mathrm{V}(\mathrm{X}_{s}) \mathrm{d}s}
\end{split}
\end{multline}

Ici, le premier terme est zéro du à \ref{kolmo_back}. Donc:

\begin{align}
\mathrm{d}(v(t, \mathrm{X}_{t}) e^{-\int_0^{t} \mathrm{V}(\mathrm{X}_{s}) \mathrm{d}s}) = \nabla v(t, \mathrm{X}_t)\mathrm{dW}_{t} e^{-\int_0^{t} \mathrm{V}(\mathrm{X}_{s}) \mathrm{d}s}
\end{align}

Finalement nous remarquons que l’espérance de $\nabla v(t, \mathrm{X}_t)\mathrm{dW}_{t} e^{-\int_0^{t} \mathrm{V}(\mathrm{X}_{s}) \mathrm{d}s}$ est égale à zéro, et donc par commutation des opérations et d’espérance, nous avons que pour toute valeur de $\beta > 0$: 

\begin{align}
\mathbb{E}(v(\beta , \mathrm{X}_{\beta})e^{-\int_0^{\beta} \mathrm{V}(\mathrm{X}_{s}}) = \mathrm{Constant}
\end{align}

Donc, nous avons que: 

\begin{align}
\mathbb{E}(v(\beta , \mathrm{X}_{\beta})e^{-\int_0^{\beta} \mathrm{V}(\mathrm{X}_{s})}) &= \mathbb{E}(v(0, \mathrm{X}_0)) \\
\mathbb{E}(g(x_{\beta}))e^{-\int_0^{\beta} \mathrm{V}(\mathrm{X}_{s})}) &= \int_{\Omega} v(0,x) f(x) \mathrm{d}x
\end{align}

où nous avons utilisé la condition initiale de \ref{kolmo_back} et l’intégration porte sur le ouvert $\Omega$ considéré. 

Considérons maintenant $\int_{\Omega} v(0,x) f(x) \mathrm{d}x$. Par la condition initiale de \ref{kolmo_forw}, nous avons:

\begin{equation}
\int_{\Omega} v(0,x) f(x) \mathrm{d}x = \int_{\Omega} v(0,x) u(0,x) \mathrm{d}x
\end{equation}

D'où:

\begin{align}
\label{expansion_integral_vu}
\begin{split}
\int_{\Omega} v(0,x) u(0,x) \mathrm{d}x &= \int_{\Omega} v(\beta, x) u(\beta,x) \mathrm{d}x - \int_{0}^{\beta} \frac{\mathrm{d}}{\mathrm{d}t}\left(\int_{\Omega} v(t,x) u(t,x) \mathrm{d}x \right) \mathrm{d}t \\
&= \int_{\Omega} v(\beta, x) u(\beta,x) \mathrm{d}x - \int_{0}^{\beta} \left( \int_{\Omega} \frac{\partial v}{\partial t} u \mathrm{d}x + \frac{\partial u}{\partial v} \mathrm{d}x \right) \mathrm{d}t
\end{split}
\end{align}

Nous avons remarqué que les équations \ref{kolmo_forw} et \ref{kolmo_back} étaient les adjoints l'un de l'autre. En d'autre terme pour si L est un opérateur différentiel et L* son opérateur adjoint, nous avons que 

\begin{align}
\label{adjoint_conditions}
\begin{split}
\frac{\partial u}{\partial t} &= \mathrm{L}u  \\
\frac{\partial v}{\partial t} &= -\mathrm{L}^{*}v
\end{split}
\end{align}

Donc les intégrales portants sur $\Omega$ ne sont que les normes $L^2$. En d'autres termes nous avons:
\begin{align}
- \int_{0}^{\beta} \left( \int_{\Omega} \frac{\partial v}{\partial t} u \mathrm{d}x + \frac{\partial u}{\partial v} \mathrm{d}x \right) \mathrm{d}t &= 
- \int_{0}^{\beta} \left( (-\mathrm{L}^{*}v,u)_{L^2} + (v, \mathrm{L}u)_{L^2} \right) \mathrm{d}t &= 0
\end{align}

Alors, nous trouvons que: 

\begin{align*}
\int_{\Omega} v(\beta, x) u(\beta, x) \mathrm{d}x &= \int_{\Omega} v(0,x) f(x) \mathrm{d}x \\
\int_{\Omega} g(x) u(\beta, x) \mathrm{d}x &= \int_{\Omega} v(0,x) f(x) \mathrm{d}x
\end{align*}

d'où nous avons le formule de Feynman-Kac 

\begin{empheq}[box=\widefbox]{align}
\label{feynman_kac}
\int_{\Omega} g(x) u(\beta,x) \mathrm{d}x &= \mathbb{E}\left( g(x_{\beta}) e^{-\int_{0}^{\beta} \mathrm{V}(x_s)\mathrm{d}s} \right)
\end{empheq}

\section{Application au problème d'intégrale de chemin} 

Nous revenons sur notre problème de départ qui est de trouver le noyau d'operateur $e^{-\beta \mathrm{H}}$. Nous rappelons que le noyau est une fonction $k_{\beta}(x,y)$ telle que:

\begin{equation}
\label{def_noyau} 
\left(e^{-\beta \mathrm{H}} f \right)(x) = \int_{\Omega} k_{\beta}(x,y) f(y) \mathrm{d}y
\end{equation}

Nous remarquons que pour $b=0$, $\left(e^{-\beta \mathrm{H}} f \right)(x)$ est la solution de \ref{kolmo_forw}. D'où nous avons, en utilisant le formule \ref{feynman_kac}:

\begin{equation}
\int_{\Omega X \Omega} k_{\beta}(x,y) f(y)g(x) \mathrm{d}x\mathrm{d}y = \mathbb{E}\left( g(x_{\beta}) e^{-\int_{0}^{\beta} \mathrm{V}(x_s)\mathrm{d}s} \right)
\end{equation}

Puisque cette derniere condition est vraie pour toute fonction $f$, nous prenons $f(y) = \delta(y)$, la fonction de Dirac. Dans ce cas, nous avons pour le processus stochastiques $\mathrm{X}_{t}$ que $\mathrm{X}_{\beta} = y + \mathrm{W}_{\beta}$. D'où:

\begin{align}
\begin{split}
\int_{\Omega} k_{\beta}(x,y) g(x) \mathrm{d}x &= \mathbb{E}\left( g(y+\mathrm{W}_{\beta}) e^{-\int_{0}^{\beta} \mathrm{V}(y+\mathrm{W}_s) \mathrm{d}s} \right) \\
&= \int_{\Omega} g(x) \mathbb{E}_{y+\mathrm{W}_{\beta}=x} \left( e^{-\int_{0}^{\beta} \mathrm{V}(y+\mathrm{W}_{s}) \mathrm{d}s} \right) \mathrm{d}x
\end{split}
\end{align}

Alors nous identifions le noyau comme étant 

\begin{empheq}[box=\widefbox]{align}
\label{noyau_esperance}
k_{\beta}(x,y) = \mathbb{E}_{y+\mathrm{W}_{\beta}=x} \left( e^{-\int_{0}^{\beta} \mathrm{V}(y+\mathrm{W}_{s}) \mathrm{d}s} \right)
\end{empheq}

\end{document} 

